# System Architecture - Local vs. Remote

**Critical Understanding:** Local models generate text. APIs give real-time data.

---

## ğŸ—ï¸ Two-Layer System

### Layer 1: Data Collection (ALWAYS APIs - Real-Time)
- âœ… **Gmail API** â†’ Pull actual emails via IMAP
- âœ… **Stripe API** â†’ Real revenue numbers, customers, charges
- âœ… **Google Calendar API** â†’ Actual calendar events
- âœ… **xAI Grok API** â†’ Real-time X (Twitter) search
- âœ… **Web Search (Brave)** â†’ Current web results
- âœ… **Clawdbot tools** â†’ Browser control, web fetch, etc.

**These NEVER use local models.** Always direct API calls for fresh, real data.

### Layer 2: Intelligence & Formatting (Local Models - Free)
- ğŸ’° **GLM-4** â†’ Summarize the data into actionable insights
- ğŸ’° **Nemotron 70B** â†’ Generate conversational responses
- ğŸ’° **Local only** â†’ No internet access, just text generation

**These process the data from Layer 1, but don't fetch new data.**

---

## ğŸ“Š Example: Morning Report Flow

```
1. REAL DATA (APIs - always fresh):
   â”œâ”€ Gmail API â†’ 3 critical emails found
   â”œâ”€ Stripe API â†’ $1.00 revenue today, $1,065 balance
   â”œâ”€ Google Calendar â†’ 2 events today
   â”œâ”€ xAI Grok â†’ No X mentions found
   â””â”€ Weather API â†’ Miami 17Â°C, cloudy

2. LOCAL INTELLIGENCE (GLM-4 - free):
   â”œâ”€ Take all the real data above
   â”œâ”€ Generate actionable summary
   â”œâ”€ Suggest priorities based on calendar/revenue
   â””â”€ Format into professional email

3. SEND (Gmail SMTP):
   â””â”€ Deliver intelligent briefing to Cooper
```

**Cost:** APIs are cheap/free, GLM is free â†’ Total: ~$0

---

## ğŸ¯ When to Use What

### ALWAYS Use APIs (Real-Time Data)
- âœ… Checking email
- âœ… Pulling Stripe revenue
- âœ… Calendar events
- âœ… X mentions search
- âœ… Web search
- âœ… Competitor monitoring
- âœ… Customer support emails

### ALWAYS Use Local Models (Text Generation)
- ğŸ’° Summarizing data into insights
- ğŸ’° Drafting email responses
- ğŸ’° Generating business analysis
- ğŸ’° Conversational responses
- ğŸ’° Weekly review narratives

### When to Use Claude API
- ğŸ§  **Complex reasoning** that local models struggle with
- ğŸ§  **Multi-step planning** requiring strong logic
- ğŸ§  **Code generation** (Claude is better than local)
- ğŸ§  **Critical decisions** where quality matters most

**Rule:** Try local first, escalate to Claude if quality isn't good enough.

---

## ğŸš¨ Critical Rule

**NEVER use local models to:**
- Search the web (they can't access internet)
- Check APIs (they don't have real-time data)
- Make decisions requiring current information
- Access databases or external services

**Local models are TEXT PROCESSORS, not DATA SOURCES.**

---

## ğŸ”„ Hybrid Intelligence

**Best of both worlds:**

```python
# 1. Get REAL data from APIs
emails = fetch_from_gmail_api()        # Real-time
revenue = fetch_from_stripe_api()      # Real-time
mentions = search_x_via_grok_api()     # Real-time

# 2. Use local model to make it intelligent
raw_data = json.dumps({
    'emails': emails,
    'revenue': revenue,
    'mentions': mentions
})

insight = call_glm(f"Analyze this business data and suggest priorities: {raw_data}")

# 3. Send actionable intelligence
send_to_cooper(insight)
```

**Result:** Fresh data + intelligent analysis, minimal cost.

---

## ğŸ’¡ Example Use Cases

### âŒ WRONG: Ask local model for weather
```python
# This would return outdated/hallucinated data
weather = call_glm("What's the weather in Miami?")  # DON'T DO THIS
```

### âœ… RIGHT: API for data, local model for summary
```python
# Get real weather
weather = curl_wttr_in("Miami")  # Real-time API

# Generate intelligent summary
summary = call_glm(f"Weather is {weather}. Should Cooper plan outdoor meetings today?")
```

### âŒ WRONG: Ask local model about X mentions
```python
mentions = call_glm("Search X for @coopwrenn mentions")  # Can't access X!
```

### âœ… RIGHT: API for search, local model for analysis
```python
# Real X search via Grok API
mentions = search_x_via_grok("@coopwrenn")  # Real-time data

# Analyze with local model
analysis = call_glm(f"These X mentions were found: {mentions}. Which need Cooper's attention?")
```

---

## ğŸ“Š Cost Breakdown

### Data Collection (APIs)
- Gmail IMAP: **FREE**
- Google Calendar: **FREE**  
- Stripe API: **FREE** (under rate limits)
- xAI Grok: **~$0.002/request** (pay-per-use)
- Brave Search: **FREE tier** (2,000 queries/month)
- Weather (wttr.in): **FREE**

**Monthly: ~$5-10 for API calls**

### Intelligence Layer
- GLM-4 (local): **$0**
- Nemotron 70B (local): **$0**

**Monthly: $0**

### Total Automation Cost
- **Before:** $60-150/month (all Claude API)
- **After:** $5-10/month (APIs) + $0 (local models)
- **Savings:** $50-140/month = **~1 month of runway preserved per year**

---

## ğŸ¯ Quality Assurance

**Monitor these to ensure local models are good enough:**
1. Cooper's feedback on morning report quality
2. Are insights actually actionable?
3. Is anything critical being missed?

**If local models aren't cutting it:**
- Fallback to Claude for that specific task
- Document why local failed
- Keep trying to improve prompts for local models

**Default strategy:** Try local, escalate to Claude if needed.

---

## ğŸ” Security Note

**Local models run on DGX** (our hardware, our control)
- No data leaves the machine during generation
- API calls still go to external services (Gmail, Stripe, etc.)
- Credentials stay local
- No third-party AI services see our business data during summarization

**This is actually MORE secure** than sending everything to Claude.

---

## ğŸ“ Summary

**The system architecture:**
1. **APIs** â†’ Get REAL data (emails, revenue, calendar, X mentions)
2. **Local Models** â†’ Process data into intelligence ($0 cost)
3. **Claude/API** â†’ Only when local quality isn't good enough (rare)

**Cooper's concern addressed:**
- âœ… Real-time internet intelligence INTACT (all APIs still used)
- âœ… X search still uses xAI Grok API (real-time)
- âœ… Web search still uses Brave API (current results)
- âœ… All external data sources still active
- âœ… Local models only process/summarize, never fetch

**We're not losing intelligence - we're getting smarter about cost!**

*Last updated: 2026-01-28 by Ritchie*
